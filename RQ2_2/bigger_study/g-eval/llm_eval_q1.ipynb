{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_json, load_txt\n",
    "from helper import parse_generated_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fact_eval_1 import FactFabricationCheckAgent\n",
    "from fact_eval_2 import FactOmissionCheckAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_q1_eval = FactFabricationCheckAgent(backend='groq', model_name='llama3-70b-8192')\n",
    "fact_q2_eval = FactOmissionCheckAgent(backend='groq', model_name='llama3-70b-8192')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = load_json(\"../../bigger_study_sample/001-108683.json\")\n",
    "first_document = case['facts'] + case['conclusion']\n",
    "\n",
    "generated_response = load_txt(\"../llama70b/001-108683_output.txt\")\n",
    "parsed_responses = parse_generated_response(generated_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no invented fact in the second document.\n"
     ]
    }
   ],
   "source": [
    "response = fact_q1_eval.generate(first_document=first_document, second_document=generated_response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is forgotten fact: The fact that the applicant requested the suspension of the execution of his sentence on account of his age and poor state of health, submitting several doctors' reports which stated that he was suffering from cerebrovascular and vertebral insufficiency as well as hypertension, and that the court refused his request (mentioned in paragraph 14 of the first document) is not mentioned in the second document.\n"
     ]
    }
   ],
   "source": [
    "response = fact_q2_eval.generate(first_document=first_document, second_document=generated_response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fact_eval_3 import FactAgent\n",
    "fact_q3_eval = FactAgent(backend='groq', model_name='llama3-70b-8192')\n",
    "response = fact_q3_eval.generate(first_document=first_document, second_document=generated_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the evaluation criteria, I will provide a score for each question from 1-5, where 1 is the lowest and 5 is the highest.\n",
      "\n",
      "**Main elements of the precedents/legal notion (identification of articles)**\n",
      "\n",
      "Score: 4\n",
      "\n",
      "The second document accurately identifies the main elements of the precedents/legal notion, specifically Article 6 ยง 1 of the European Convention on Human Rights (ECHR), which is the relevant article related to the length of the criminal proceedings and the non-communication of the Principal Public Prosecutor's written opinion. The document also correctly mentions that the applicant alleged a violation of Article 6 ยง 1 of the ECHR.\n",
      "\n",
      "**Identification of factual circumstances**\n",
      "\n",
      "Score: 4\n",
      "\n",
      "The second document generally accurately identifies the factual circumstances of the case, including the applicant's complaints, the criminal proceedings, and the non-communication of the Principal Public Prosecutor's written opinion. However, there are some minor inaccuracies and omissions, such as the exact dates of the acquittals and convictions, and the specific reasons for the Court of Cassation quashing several judgments due to procedural errors.\n",
      "\n",
      "**Additional evaluation**\n",
      "\n",
      "Upon reviewing the second document, I noticed the following:\n",
      "\n",
      "1. There is no fact in the first document that was never mentioned in the second document.\n",
      "2. There is no invented fact in the second document that was not present in the first document.\n",
      "3. The second document generally clearly distinguishes between factual information and legal principles, although there are some minor instances where the language could be improved for better clarity.\n",
      "\n",
      "Overall, the second document demonstrates a good understanding of the main elements of the precedents/legal notion and the factual circumstances of the case. However, there is room for improvement in terms of accuracy and completeness of the factual information.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided documents, I will evaluate the second document based on the following criteria:\n",
      "\n",
      "**1. Misrepresentation of Central Legal Issues:**\n",
      "\n",
      "The second document accurately represents the central legal issues in the case, including the length of the criminal proceedings and the non-communication of the Principal Public Prosecutor's written opinion to the applicant during the appeal proceedings. The document correctly identifies the relevant articles of the European Convention on Human Rights (ECHR) and the domestic law and practice in Turkey.\n",
      "\n",
      "**Score: 9/10**\n",
      "\n",
      "**2. Failure to Recognize Nuances in Legal Concepts and Articles:**\n",
      "\n",
      "The second document demonstrates a good understanding of the legal concepts and articles relevant to the case. However, in some instances, the language used is somewhat simplistic, and the document could benefit from more nuanced explanations of the legal principles involved. For example, the document could have provided more detail on the specific requirements of Article 6 ยง 1 of the ECHR and how they were breached in this case.\n",
      "\n",
      "**Score: 8/10**\n",
      "\n",
      "**3. Incorrect Application of Legal Standards:**\n",
      "\n",
      "The second document accurately applies the legal standards relevant to the case. The document correctly identifies the violations of Article 6 ยง 1 of the ECHR and explains how the domestic law and practice in Turkey were breached.\n",
      "\n",
      "**Score: 10/10**\n",
      "\n",
      "**4. Inadequate Connection Between Legal Notions and Factual Circumstances:**\n",
      "\n",
      "The second document generally provides a good connection between the legal notions and factual circumstances of the case. However, in some instances, the document could have provided more detail on the specific factual circumstances that led to the breaches of the ECHR. For example, the document could have explained more fully how the multiple acquittals and convictions affected the length of the proceedings and the applicant's right to a fair trial.\n",
      "\n",
      "**Score: 8.5/10**\n",
      "\n",
      "Overall, the second document provides a good summary of the case and accurately applies the relevant legal standards. However, it could benefit from more nuanced explanations of the legal principles involved and more detailed connections between the legal notions and factual circumstances of the case.\n",
      "\n",
      "**Total Score: 35.5/40**\n"
     ]
    }
   ],
   "source": [
    "from eval_2 import EvalTwoAgent\n",
    "e2_eval = EvalTwoAgent(backend='groq', model_name='llama3-70b-8192')\n",
    "response = e2_eval.generate(first_document=first_document, second_document=generated_response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
