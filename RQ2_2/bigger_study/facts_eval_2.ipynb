{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import networkx as nx\n",
    "from dateutil.parser import parse as date_parse\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Load models\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "legal_bert_tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "legal_bert_model = AutoModelForSequenceClassification.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "legal_classifier = pipeline(\"text-classification\", model=legal_bert_model, tokenizer=legal_bert_tokenizer)\n",
    "\n",
    "class LegalFactChecker:\n",
    "    def __init__(self):\n",
    "        self.legal_kb = self.load_legal_kb()\n",
    "\n",
    "    def load_legal_kb(self) -> Dict:\n",
    "        # Simplified legal knowledge base\n",
    "        return {\n",
    "            \"legal_aid\": {\n",
    "                \"entities\": [\"Scottish Legal Aid Board\"],\n",
    "                \"procedures\": [\"application\", \"refusal\", \"granting\"],\n",
    "                \"conditions\": [\"financial eligibility\", \"merits test\"]\n",
    "            },\n",
    "            \"appeal\": {\n",
    "                \"entities\": [\"High Court of Justiciary\", \"Appeal Court\"],\n",
    "                \"procedures\": [\"lodging\", \"hearing\", \"decision\"],\n",
    "                \"grounds\": [\"miscarriage of justice\", \"error in law\"]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def extract_facts(self, text: str) -> List[Dict]:\n",
    "        doc = nlp(text)\n",
    "        facts = []\n",
    "        for sent in doc.sents:\n",
    "            for token in sent:\n",
    "                if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
    "                    fact = {\n",
    "                        'predicate': token.lemma_,\n",
    "                        'subject': ' '.join([t.text for t in token.subtree if t.dep_ == \"nsubj\"]),\n",
    "                        'object': ' '.join([t.text for t in token.subtree if t.dep_ in [\"dobj\", \"pobj\"]]),\n",
    "                        'text': sent.text\n",
    "                    }\n",
    "                    facts.append(fact)\n",
    "        return facts\n",
    "\n",
    "    def extract_entities(self, text: str) -> Dict[str, List[str]]:\n",
    "        doc = nlp(text)\n",
    "        entities = {}\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ not in entities:\n",
    "                entities[ent.label_] = []\n",
    "            entities[ent.label_].append(ent.text)\n",
    "        return entities\n",
    "\n",
    "    def extract_dates(self, text: str) -> List[Tuple[str, str]]:\n",
    "        date_pattern = r'\\b(\\d{1,2}\\s+\\w+\\s+\\d{4}|\\d{4})\\b'\n",
    "        matches = re.findall(date_pattern, text)\n",
    "        return [(match, str(date_parse(match))) for match in matches]\n",
    "\n",
    "    def build_event_graph(self, facts: List[Dict]) -> nx.DiGraph:\n",
    "        G = nx.DiGraph()\n",
    "        for i, fact in enumerate(facts):\n",
    "            G.add_node(i, **fact)\n",
    "            for j, other_fact in enumerate(facts):\n",
    "                if i != j:\n",
    "                    if fact['subject'] in other_fact['text'] or fact['object'] in other_fact['text']:\n",
    "                        G.add_edge(i, j)\n",
    "        return G\n",
    "\n",
    "    def check_temporal_consistency(self, dates: List[Tuple[str, str]]) -> List[str]:\n",
    "        inconsistencies = []\n",
    "        sorted_dates = sorted(dates, key=lambda x: date_parse(x[1]))\n",
    "        for i in range(len(sorted_dates) - 1):\n",
    "            if (date_parse(sorted_dates[i+1][1]) - date_parse(sorted_dates[i][1])).days < 0:\n",
    "                inconsistencies.append(f\"Temporal inconsistency: {sorted_dates[i][0]} is after {sorted_dates[i+1][0]}\")\n",
    "        return inconsistencies\n",
    "\n",
    "    def validate_legal_claims(self, facts: List[Dict]) -> List[str]:\n",
    "        invalid_claims = []\n",
    "        for fact in facts:\n",
    "            legal_context = legal_classifier(fact['text'])[0]\n",
    "            if legal_context['label'] in self.legal_kb:\n",
    "                kb_entry = self.legal_kb[legal_context['label']]\n",
    "                if not any(entity in fact['text'] for entity in kb_entry['entities']):\n",
    "                    invalid_claims.append(f\"Missing legal entity in claim: {fact['text']}\")\n",
    "                if not any(proc in fact['text'] for proc in kb_entry['procedures']):\n",
    "                    invalid_claims.append(f\"Invalid legal procedure in claim: {fact['text']}\")\n",
    "        return invalid_claims\n",
    "\n",
    "    def compare_facts(self, original_facts: List[Dict], generated_facts: List[Dict]) -> List[str]:\n",
    "        fabrications = []\n",
    "        for gen_fact in generated_facts:\n",
    "            if not any(self.fact_similarity(gen_fact, orig_fact) > 0.8 for orig_fact in original_facts):\n",
    "                fabrications.append(f\"Potential fabrication: {gen_fact['text']}\")\n",
    "        return fabrications\n",
    "\n",
    "    def fact_similarity(self, fact1: Dict, fact2: Dict) -> float:\n",
    "        # Simplified similarity measure\n",
    "        elements1 = set([fact1['predicate'], fact1['subject'], fact1['object']])\n",
    "        elements2 = set([fact2['predicate'], fact2['subject'], fact2['object']])\n",
    "        return len(elements1 & elements2) / len(elements1 | elements2)\n",
    "\n",
    "    def check_fabrication(self, original_text: str, generated_text: str) -> Dict:\n",
    "        original_facts = self.extract_facts(original_text)\n",
    "        generated_facts = self.extract_facts(generated_text)\n",
    "        original_entities = self.extract_entities(original_text)\n",
    "        generated_entities = self.extract_entities(generated_text)\n",
    "        original_dates = self.extract_dates(original_text)\n",
    "        generated_dates = self.extract_dates(generated_text)\n",
    "\n",
    "        fact_fabrications = self.compare_facts(original_facts, generated_facts)\n",
    "        entity_fabrications = {k: list(set(v) - set(original_entities.get(k, []))) for k, v in generated_entities.items()}\n",
    "        temporal_inconsistencies = self.check_temporal_consistency(generated_dates)\n",
    "        invalid_legal_claims = self.validate_legal_claims(generated_facts)\n",
    "\n",
    "        original_graph = self.build_event_graph(original_facts)\n",
    "        generated_graph = self.build_event_graph(generated_facts)\n",
    "        structural_inconsistencies = [\n",
    "            f\"Structural inconsistency in event {i}\" \n",
    "            for i in range(len(generated_facts)) \n",
    "            if i in generated_graph and generated_graph.out_degree(i) != original_graph.out_degree(i)\n",
    "        ]\n",
    "\n",
    "        return {\n",
    "            \"fact_fabrications\": fact_fabrications,\n",
    "            \"entity_fabrications\": entity_fabrications,\n",
    "            \"temporal_inconsistencies\": temporal_inconsistencies,\n",
    "            \"invalid_legal_claims\": invalid_legal_claims,\n",
    "            \"structural_inconsistencies\": structural_inconsistencies\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_json, load_txt\n",
    "original_text = load_json(\"../bigger_study_sample/001-57899.json\")['facts']\n",
    "generated_text = load_txt(\"./gpt-4/001-57899.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fact Fabrications:\n",
      "- Potential fabrication: **Answer:**  \n",
      "The case involves Mr. Anthony Boner, a British citizen, born in 1960, who was convicted of multiple criminal offenses, including assault and armed robbery, in a trial held in the High Court of Justiciary, Scotland, between March 29 and April 10, 1990.\n",
      "- Potential fabrication: \n",
      "   - Mr. Boner, along with two others, was arrested following an investigation and was charged with assault, armed robbery, wilful damage, and firearm-related offenses.\n",
      "- Potential fabrication: - During the trial, a witness, Mrs. G., was allowed to give evidence after being present in the courtroom before her testimony, which the defense objected to.\n",
      "- Potential fabrication: The trial judge ruled that her earlier presence did not affect the fairness of her testimony.\n",
      "- Potential fabrication: Mrs. G.'s evidence implicated Mr. Boner in the robbery.\n",
      "- Potential fabrication: \n",
      "   - The jury found Mr. Boner guilty of all charges, and he was sentenced to eight years in prison.\n",
      "- Potential fabrication: \n",
      "   - Mr. Boner filed an appeal against his conviction, but his solicitors and counsel withdrew support, as they did not believe there were substantial grounds for appeal.\n",
      "- Potential fabrication: **European Court of Human Rights (ECHR):** Ultimately ruled on the violation of Mr. Boner’s rights under Article 6 para. 3 (c) of the European Convention on Human Rights.\n",
      "\n",
      "3.\n",
      "- Potential fabrication: Specifically, it was argued that the \"interests of justice\" required legal representation during Mr. Boner’s appeal hearing, especially since he lacked legal knowledge, while the Crown was represented by counsel.\n",
      "- Potential fabrication: Despite the withdrawal of his legal aid due to insufficient grounds for appeal, Mr. Boner represented himself in the appeal.\n",
      "- Potential fabrication: The European Court of Human Rights found that the failure to provide Mr. Boner with free legal assistance during his appeal hearing amounted to a violation of Article 6 para. 3 (c), as the \"interests of justice\" required legal representation.\n",
      "\n",
      "Entity Fabrications:\n",
      "- PERSON\n",
      "- NORP\n",
      "- DATE\n",
      "- ORG\n",
      "- GPE\n",
      "- CARDINAL\n",
      "- LAW\n",
      "\n",
      "Structural Inconsistencies:\n",
      "- Structural inconsistency in event 0\n",
      "- Structural inconsistency in event 1\n",
      "- Structural inconsistency in event 3\n",
      "- Structural inconsistency in event 4\n",
      "- Structural inconsistency in event 5\n",
      "- Structural inconsistency in event 6\n",
      "- Structural inconsistency in event 7\n",
      "- Structural inconsistency in event 8\n",
      "- Structural inconsistency in event 9\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "checker = LegalFactChecker()\n",
    "\n",
    "\n",
    "results = checker.check_fabrication(original_text, generated_text)\n",
    "\n",
    "for category, issues in results.items():\n",
    "    if issues:\n",
    "        print(f\"\\n{category.replace('_', ' ').title()}:\")\n",
    "        for issue in issues:\n",
    "            print(f\"- {issue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis24",
   "language": "python",
   "name": "thesis24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
