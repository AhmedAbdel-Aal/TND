{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama\n",
    "import json\n",
    "from summary_agent import SummaryAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "i1_case =  load_json('../data/echr-processed/001-61521.json')\n",
    "i2_case = load_json('../data/echr-processed/001-57416.json')\n",
    "i3_case = load_json('../data/echr-processed/001-205675.json')\n",
    "i4_case = load_json('../data/echr-processed/001-225326.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_agent = SummaryAgent(backend=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['itemid', 'importance', 'judgementdate', '__articles', '__conclusion', 'appno', 'article', 'extractedappno', 'docname', 'parties', 'rank', 'cite', 'procedure', 'facts', 'law', 'conclusion'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i4_case.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing procedure\n",
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n",
      "Summarizing facts\n",
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n",
      "Summarizing law\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n",
      "Summarizing conclusion\n",
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n"
     ]
    }
   ],
   "source": [
    "summary_i4case = summary_agent.summarize_case(i4_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing procedure\n",
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n",
      "Summarizing facts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9617 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9617 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text has 7589 words and 335 sentences, on average 22.65373134328358 word/sentecesand 9617 tokens, token limit is 7500\n",
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n",
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n",
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n",
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n",
      "Summarizing law\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8971 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8971 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text has 7238 words and 258 sentences, on average 28.05426356589147 word/sentecesand 8971 tokens, token limit is 7500\n",
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n",
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n",
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n",
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n",
      "Summarizing conclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (918 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   init_summary ....\n",
      "   reflect ....\n",
      "   improve ....\n"
     ]
    }
   ],
   "source": [
    "summary_i1case = summary_agent.summarize_case(i1_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./001-57416.json', 'w') as f:\n",
    "    json.dump(i4_case, f, indent=4)\n",
    "with open('./001-57416_summary.json', 'w') as f:\n",
    "    json.dump(summary_i4case, f, indent=4)\n",
    "\n",
    "    \n",
    "with open('./001-61521.json', 'w') as f:\n",
    "    json.dump(i1_case, f, indent=4)\n",
    "with open('./001-61521_summary.json', 'w') as f:\n",
    "    json.dump(summary_i1case, f, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decides to join the applications;\n",
      "Decides that Ms Olena Oleksandrivna Kruhlova, the wife of the applicant in application no. 25946/19, has standing to continue the present proceedings in his stead;\n",
      "Declares the applications admissible;\n",
      "Holds that these applications disclose a breach of Article 6 1 and Article 13 of the Convention concerning the excessive length of criminal proceedings and the lack of any effective remedy in domestic law;\n",
      "Holds\n",
      "that the respondent State is to pay the applicants, within three months, the amounts indicated in the appended table, to be converted into the currency of the respondent State at the rate applicable at the date of settlement;\n",
      "that from the expiry of the above-mentioned three months until settlement simple interest shall be payable on the above amounts at a rate equal to the marginal lending rate of the European Central Bank during the default period plus three percentage points.\n",
      "Done in English, and notified in writing on 22 June 2023, pursuant to Rule 77 2 and 3 of the Rules of Court.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(i4_case['conclusion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The European Court of Human Rights (ECHR) combines two separate applications into one case. Ms. Olena Oleksandrivna Kruhlova, the wife of one applicant, is authorized to proceed with the case on behalf of her husband. The ECHR determines that the combined applications are admissible. The Court further finds a violation of Articles 6 and 13, citing excessive criminal proceedings and inadequate domestic remedies. The respondent State is required to pay the applicants a total of [amount] within three months, with simple interest accruing at a rate equal to the marginal lending rate of the European Central Bank plus three percentage points.\n"
     ]
    }
   ],
   "source": [
    "print(summary_i4case['conclusion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Holds that there has been a violation of the respondent State's positive obligations under both Articles 3 and 8 of the Convention;\n",
      "2. Holds that no separate issue arises under Article 13 of the Convention;\n",
      "3. Holds that it is not necessary to examine the applicant's complaints under Article 14 of the Convention;\n",
      "4. Holds\n",
      "(a) that the respondent State is to pay the applicant, within three months from the date on which the judgment becomes final according to Article 44 2 of the Convention, the following amounts, to be converted into the national currency of the respondent State at the rate applicable at the date of settlement:\n",
      "(b) that from the expiry of the above-mentioned three months until settlement simple interest shall be payable on the above amounts at a rate equal to the marginal lending rate of the European Central Bank during the default period plus three percentage points;\n",
      "5. Dismisses the remainder of the applicant's claim for just satisfaction.\n",
      "Done in English, and notified in writing on 4 December 2003, pursuant to Rule 77 2 and 3 of the Rules of Court.\n",
      "In accordance with Article 45 2 of the Convention and Rule 74 2 of the Rules of Court, the concurring opinion of Mrs Tulkens is annexed to this judgment.\n",
      "In this particularly sensitive and delicate case, I should simply like to make a few additional observations.\n",
      "1. I consider that it was important and significant that the Court should examine the case under both Article 3 and Article 8 of the Convention. Rape infringes not only the right to personal integrity (both physical and psychological) as guaranteed by Article 3, but also the right to autonomy as a component of the right to respect for private life as guaranteed by Article 8.\n",
      "2. I agree entirely with the Court's general approach (see paragraphs 148 et seq. of the judgment) and the manner in which it was applied in the present case (see paragraphs 169 et seq.). The only point I wish to clarify concerns the use of criminal remedies. Relying, in particular, on X and Y v. the Netherlands (judgment of 26 March 1985, Series A no. 91), the Court considers that States have a positive obligation inherent in Articles 3 and 8 of the Convention to enact criminal-law provisions effectively punishing rape (see paragraph 153). Admittedly, recourse to the criminal law may be understandable where offences of this kind are concerned. However, it is also important to emphasise on a more general level, as, indeed, the Court did in X and Y v. the Netherlands itself, that [r]ecourse to the criminal law is not necessarily the only answer (p. 12, 24 in fine). I consider that criminal proceedings should remain, both in theory and in practice, a last resort or subsidiary remedy and that their use, even in the context of positive obligations, calls for a certain degree of restraint . As to the assumption that criminal remedies are, in any event, the most effective in terms of deterrence, the observations set out in the Report on Decriminalisation by the European Committee on Crime Problems clearly show that the effectiveness of general deterrence based on the criminal law depends on various factors and that such an approach is not the only way of preventing undesirable behaviour .\n",
      "3. That said, in the present case, as in X and Y v. the Netherlands (p. 13, 27), once the State has opted for a system of protection based on the criminal law, it is of course essential that the relevant criminal-law provisions are fully and rigorously applied in order to provide the applicant with practical and effective protection. In that connection, the Court's observation that [t]he investigation and its conclusion must be centred on the issue of non-consent (see paragraph 181 of the present judgment) is, in my opinion, of fundamental importance.\n",
      "3. That said, in the present case, as in X and Y v. the Netherlands (p. 13, 27), once the State has opted for a system of protection based on the criminal law, it is of course essential that the relevant criminal-law provisions are fully and rigorously applied in order to provide the applicant with practical and effective protection. In that connection, the Court's observation that [t]he investigation and its conclusion must be centred on the issue of non-consent (see paragraph 181 of the present judgment) is, in my opinion, of fundamental importance.\n"
     ]
    }
   ],
   "source": [
    "print(i1_case['conclusion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The European Court of Human Rights holds that there has been a violation of both Articles 3 and 8 of the Convention, resulting from the respondent State's positive obligations. The Court finds no separate issue arises under Article 13. The Court does not examine the applicant's complaints under Article 14. As a remedy, the respondent State is required to pay the applicant a certain amount within three months from the date on which the judgment becomes final. Simple interest will be payable at a rate equal to the marginal lending rate of the European Central Bank during the default period plus three percentage points. The remainder of the applicant's claim is dismissed.\n"
     ]
    }
   ],
   "source": [
    "print(summary_i1case['conclusion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i4_string = json.dumps(i4_case)\n",
    "i4s_string = json.dumps(summary_i4case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44700"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i1_case['facts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from nltk import tokenize\n",
    "\n",
    "def count_tokens(text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    num_tokens = len(tokens)\n",
    "    return num_tokens\n",
    "\n",
    "def get_sentences(text):\n",
    "    sentences = tokenize.sent_tokenize(i1_case['facts'])\n",
    "    merged_sentences = []\n",
    "\n",
    "    sentence = ''\n",
    "    for idx, i in enumerate(sentences):\n",
    "        sentence += i\n",
    "        if len(i) < 10:\n",
    "            continue\n",
    "        else:\n",
    "            merged_sentences.append(sentence)\n",
    "            sentence = ''\n",
    "    \n",
    "    return merged_sentences\n",
    "\n",
    "def overlapping_split(text, token_limit=7500, overlap = 300):\n",
    "    words = len(text.split(' '))\n",
    "    num_tokens = count_tokens(text)\n",
    "    sentences = get_sentences(text)\n",
    "    print(f'text has {words} words and {len(sentences)} sentences, on average {words/len(sentences)} word/sentecesand {num_tokens} tokens, token limit is {token_limit}')\n",
    "    \n",
    "    if num_tokens <= token_limit:\n",
    "        return text\n",
    "    \n",
    "    chuncks = (num_tokens // token_limit) + 1 + 1\n",
    "    sentences_in_chunck = (len(sentences) // chuncks) - 10\n",
    "    spliited_sentences = [sentences[i:i+sentences_in_chunck] for i in range(0, len(sentences), sentences_in_chunck)]\n",
    "    return spliited_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9617 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text has 7589 words and 335 sentences, on average 22.65373134328358 word/sentecesand 9617 tokens, token limit is 7500\n"
     ]
    }
   ],
   "source": [
    "spliited_sentences = overlapping_split(i1_case['facts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spliited_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2023 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2714 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 2714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3310 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 3310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 1567\n"
     ]
    }
   ],
   "source": [
    "for i in spliited_sentences:\n",
    "    sent = ' '.join(i)\n",
    "    num_tokens = count_tokens(sent)\n",
    "    print(len(i), num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "sentences = tokenize.sent_tokenize(i1_case['facts'])\n",
    "merged_sentences = []\n",
    "\n",
    "sentence = ''\n",
    "for idx, i in enumerate(sentences):\n",
    "    sentence += i\n",
    "    if len(i) < 10:\n",
    "        continue\n",
    "    else:\n",
    "        merged_sentences.append(sentence)\n",
    "        sentence = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "59\n",
      "120\n",
      "134\n",
      "56\n",
      "26\n",
      "155\n",
      "35\n",
      "78\n",
      "66\n",
      "48\n",
      "101\n",
      "98\n",
      "47\n",
      "63\n",
      "104\n",
      "142\n",
      "63\n",
      "67\n",
      "62\n",
      "29\n",
      "129\n",
      "39\n",
      "78\n",
      "185\n",
      "66\n",
      "69\n",
      "114\n",
      "120\n",
      "59\n",
      "79\n",
      "86\n",
      "82\n",
      "37\n",
      "17\n",
      "100\n",
      "183\n",
      "72\n",
      "98\n",
      "78\n",
      "220\n",
      "47\n",
      "110\n",
      "29\n",
      "115\n",
      "217\n",
      "117\n",
      "58\n",
      "239\n",
      "68\n",
      "64\n",
      "111\n",
      "43\n",
      "103\n",
      "56\n",
      "189\n",
      "97\n",
      "25\n",
      "45\n",
      "44\n",
      "150\n",
      "41\n",
      "82\n",
      "73\n",
      "40\n",
      "104\n",
      "15\n",
      "175\n",
      "91\n",
      "117\n",
      "45\n",
      "61\n",
      "42\n",
      "23\n",
      "151\n",
      "59\n",
      "36\n",
      "78\n",
      "118\n",
      "188\n",
      "37\n",
      "82\n",
      "100\n",
      "34\n",
      "105\n",
      "13\n",
      "158\n",
      "30\n",
      "14\n",
      "95\n",
      "26\n",
      "163\n",
      "23\n",
      "104\n",
      "18\n",
      "142\n",
      "217\n",
      "45\n",
      "129\n",
      "46\n",
      "64\n",
      "107\n",
      "168\n",
      "41\n",
      "111\n",
      "70\n",
      "129\n",
      "113\n",
      "94\n",
      "155\n",
      "104\n",
      "120\n",
      "92\n",
      "260\n",
      "56\n",
      "104\n",
      "284\n",
      "72\n",
      "209\n",
      "30\n",
      "78\n",
      "94\n",
      "71\n",
      "45\n",
      "56\n",
      "58\n",
      "92\n",
      "64\n",
      "48\n",
      "23\n",
      "30\n",
      "98\n",
      "68\n",
      "90\n",
      "26\n",
      "41\n",
      "87\n",
      "103\n",
      "142\n",
      "24\n",
      "75\n",
      "81\n",
      "185\n",
      "105\n",
      "85\n",
      "195\n",
      "197\n",
      "70\n",
      "50\n",
      "113\n",
      "34\n",
      "238\n",
      "89\n",
      "120\n",
      "144\n",
      "71\n",
      "148\n",
      "81\n",
      "93\n",
      "146\n",
      "345\n",
      "168\n",
      "175\n",
      "248\n",
      "118\n",
      "91\n",
      "257\n",
      "177\n",
      "140\n",
      "144\n",
      "94\n",
      "104\n",
      "111\n",
      "123\n",
      "80\n",
      "93\n",
      "215\n",
      "294\n",
      "335\n",
      "192\n",
      "92\n",
      "264\n",
      "158\n",
      "110\n",
      "150\n",
      "264\n",
      "74\n",
      "343\n",
      "23\n",
      "300\n",
      "260\n",
      "107\n",
      "52\n",
      "225\n",
      "271\n",
      "154\n",
      "209\n",
      "127\n",
      "109\n",
      "224\n",
      "75\n",
      "155\n",
      "41\n",
      "135\n",
      "45\n",
      "171\n",
      "142\n",
      "31\n",
      "25\n",
      "270\n",
      "183\n",
      "18\n",
      "167\n",
      "123\n",
      "30\n",
      "37\n",
      "27\n",
      "42\n",
      "196\n",
      "158\n",
      "242\n",
      "269\n",
      "29\n",
      "24\n",
      "88\n",
      "30\n",
      "25\n",
      "91\n",
      "270\n",
      "265\n",
      "185\n",
      "315\n",
      "18\n",
      "253\n",
      "29\n",
      "281\n",
      "57\n",
      "107\n",
      "76\n",
      "231\n",
      "42\n",
      "220\n",
      "128\n",
      "192\n",
      "135\n",
      "161\n",
      "186\n",
      "148\n",
      "35\n",
      "62\n",
      "69\n",
      "185\n",
      "87\n",
      "187\n",
      "62\n",
      "264\n",
      "179\n",
      "52\n",
      "288\n",
      "285\n",
      "354\n",
      "291\n",
      "293\n",
      "338\n",
      "179\n",
      "168\n",
      "154\n",
      "56\n",
      "207\n",
      "225\n",
      "318\n",
      "47\n",
      "153\n",
      "162\n",
      "27\n",
      "142\n",
      "25\n",
      "109\n",
      "39\n",
      "65\n",
      "106\n",
      "36\n",
      "13\n",
      "216\n",
      "26\n",
      "66\n",
      "68\n",
      "13\n",
      "176\n",
      "26\n",
      "109\n",
      "436\n",
      "56\n",
      "328\n",
      "377\n",
      "269\n",
      "263\n",
      "366\n",
      "131\n",
      "205\n",
      "344\n",
      "58\n",
      "42\n",
      "660\n",
      "229\n",
      "139\n",
      "225\n",
      "532\n",
      "519\n",
      "148\n",
      "162\n",
      "132\n",
      "135\n",
      "179\n",
      "289\n",
      "278\n",
      "141\n",
      "266\n",
      "334\n",
      "158\n",
      "222\n",
      "156\n",
      "132\n",
      "455\n",
      "184\n",
      "242\n",
      "108\n",
      "200\n",
      "421\n",
      "120\n",
      "112\n",
      "90\n",
      "102\n",
      "87\n",
      "486\n"
     ]
    }
   ],
   "source": [
    "for i in merged_sentences:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9617 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text has 44700 words and 9617 tokens, token limit is 7500\n"
     ]
    }
   ],
   "source": [
    "overlapping_split(i1_case['facts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = i1_case['facts'].split('.')\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE CIRCUMSTANCES OF THE CASE\\n9.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 335)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(merged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I.THE CIRCUMSTANCES OF THE CASE\\n9.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./i4_case.json', 'w') as f:\n",
    "    json.dump(summary_reposne, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
